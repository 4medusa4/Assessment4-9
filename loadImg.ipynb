{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# width and height for resizing\n",
    "width = 224\n",
    "height = 224\n",
    "\n",
    "# directory where images are stored\n",
    "base_dir = 'D:/NIBM/Machine Learning/Assessment_4/9'\n",
    "\n",
    "# store preprocessed images and labels\n",
    "preprocessed_images = []\n",
    "labels = []\n",
    "\n",
    "# check all directories in the base directory\n",
    "for dirname in os.listdir(base_dir):\n",
    "    # check over all images in the directory\n",
    "    for filename in os.listdir(os.path.join(base_dir, dirname)):\n",
    "        if filename.endswith('.jpg'):  # or '.png' or '.jpeg' or whatever your image format is\n",
    "            # load the image\n",
    "            img = Image.open(os.path.join(base_dir, dirname, filename))\n",
    "\n",
    "            # resize the image\n",
    "            img = img.resize((width, height))\n",
    "\n",
    "            # vonvert the image to a NumPy array\n",
    "            img_array = np.array(img)\n",
    "\n",
    "            # normalize the pixel values\n",
    "            img_array = img_array / 255.0\n",
    "\n",
    "            # add the preprocessed image and label to the lists\n",
    "            preprocessed_images.append(img_array)\n",
    "            labels.append(dirname)\n",
    "\n",
    "# convert the lists to NumPy arrays\n",
    "preprocessed_images = np.array(preprocessed_images)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# convert labels to numerical values\n",
    "le = LabelEncoder()\n",
    "labels = le.fit_transform(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "26/26 [==============================] - 21s 776ms/step - loss: 2.1980 - accuracy: 0.2809\n",
      "Epoch 2/10\n",
      "26/26 [==============================] - 22s 845ms/step - loss: 1.2234 - accuracy: 0.4183\n",
      "Epoch 3/10\n",
      "26/26 [==============================] - 26s 1s/step - loss: 0.9301 - accuracy: 0.6114\n",
      "Epoch 4/10\n",
      "26/26 [==============================] - 24s 922ms/step - loss: 0.7467 - accuracy: 0.6955\n",
      "Epoch 5/10\n",
      "26/26 [==============================] - 24s 921ms/step - loss: 0.4202 - accuracy: 0.8465\n",
      "Epoch 6/10\n",
      "26/26 [==============================] - 24s 918ms/step - loss: 0.2169 - accuracy: 0.9233\n",
      "Epoch 7/10\n",
      "26/26 [==============================] - 25s 961ms/step - loss: 0.2234 - accuracy: 0.9418\n",
      "Epoch 8/10\n",
      "26/26 [==============================] - 25s 960ms/step - loss: 0.1539 - accuracy: 0.9480\n",
      "Epoch 9/10\n",
      "26/26 [==============================] - 24s 937ms/step - loss: 0.0469 - accuracy: 0.9889\n",
      "Epoch 10/10\n",
      "26/26 [==============================] - 24s 930ms/step - loss: 0.0130 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x107a461dbb0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "num_classes = len(np.unique(labels))\n",
    "\n",
    "# Define the model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(width, height, 3)),  # width, height should be the dimensions of your images\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(num_classes)  # num_classes should be the number of classes in your dataset\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(preprocessed_images, labels, epochs=10)  # preprocessed_images should be your preprocessed images, labels should be your labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "21/21 [==============================] - 24s 1s/step - loss: 0.0836 - accuracy: 0.9830 - val_loss: 0.0263 - val_accuracy: 0.9877\n",
      "Epoch 2/10\n",
      "21/21 [==============================] - 23s 1s/step - loss: 0.0220 - accuracy: 0.9938 - val_loss: 0.6194 - val_accuracy: 0.8765\n",
      "Epoch 3/10\n",
      "21/21 [==============================] - 25s 1s/step - loss: 0.1521 - accuracy: 0.9582 - val_loss: 3.2301 - val_accuracy: 0.4877\n",
      "Epoch 4/10\n",
      "21/21 [==============================] - 23s 1s/step - loss: 0.0467 - accuracy: 0.9938 - val_loss: 1.5118 - val_accuracy: 0.7716\n",
      "Epoch 5/10\n",
      "21/21 [==============================] - 23s 1s/step - loss: 0.0086 - accuracy: 0.9969 - val_loss: 0.2957 - val_accuracy: 0.9259\n",
      "Epoch 6/10\n",
      "21/21 [==============================] - 26s 1s/step - loss: 0.0103 - accuracy: 0.9985 - val_loss: 1.9714 - val_accuracy: 0.7407\n",
      "Epoch 7/10\n",
      "21/21 [==============================] - 27s 1s/step - loss: 0.0205 - accuracy: 0.9954 - val_loss: 0.3825 - val_accuracy: 0.9136\n",
      "Epoch 8/10\n",
      "21/21 [==============================] - 27s 1s/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 3.7728 - val_accuracy: 0.6235\n",
      "Epoch 9/10\n",
      "21/21 [==============================] - 28s 1s/step - loss: 0.0087 - accuracy: 0.9969 - val_loss: 1.0409 - val_accuracy: 0.8457\n",
      "Epoch 10/10\n",
      "21/21 [==============================] - 28s 1s/step - loss: 0.0064 - accuracy: 0.9985 - val_loss: 1.9423 - val_accuracy: 0.7716\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have already defined your model and compiled it\n",
    "# and your data is stored in preprocessed_images and labels\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(preprocessed_images, labels, epochs=10, validation_split=0.2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 - 1s - loss: 0.1830 - accuracy: 0.9753 - 1s/epoch - 194ms/step\n",
      "\n",
      "Test accuracy: 0.9753086566925049\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have already split your data into training and testing sets\n",
    "# and your test data is stored in test_images and test_labels\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_images, test_images, train_labels, test_labels = train_test_split(\n",
    "    preprocessed_images, labels, test_size=0.2, random_state=42\n",
    ")\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)\n",
    "\n",
    "\n",
    "print('\\nTest accuracy:',test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming model is your trained model\n",
    "model.save('cw_classifier_model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nibm-ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
